{
    "cells": [{
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Replica project\n",
                "\n",
                "### Clustering efforts\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [{
                "name": "stderr",
                "output_type": "stream",
                "text": [
                    "2022-06-11 15:19:09.306757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
                ]
            }],
            "source": [
                "# loading the metadata\n",
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import pickle\n",
                "import sys\n",
                "import sklearn\n",
                "\n",
                "\n",
                "sys.path.insert(0, \"../model/\")\n",
                "from utils import *\n",
                "\n",
                "sys.path.insert(0, \"../web_annotation/\")\n",
                "from utils_clusters import *\n",
                "from metrics_clusters import * \n",
                "\n",
                "\n",
                "data_dir = '/scratch/students/schaerf/'\n",
                "#data_dir = '../data/'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Making the clusters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "type_clustering = input() #'dbscan'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [],
            "source": [
                "subfolder_dir = input() #'25-05-2022'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "if type_clustering in ['dbscan', 'optics']:\n",
                "    dist = float(input()) #1200\n",
                "else:\n",
                "    dist = int(input()) #1200"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "dist2 = float(input()) #0.12"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": [
                "effort = int(input()) #0,1,2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": [
                "if effort == 0:\n",
                "    data_file = 'data_sample.csv'\n",
                "elif effort == 3:\n",
                "    data_file = 'data.csv'\n",
                "else:\n",
                "    data_file = subfolder_dir + '/data_retrain_'+str(effort)+'.csv'\n",
                "\n",
                "embeds_file = subfolder_dir + '/resnext-101_'+subfolder_dir+'.npy'\n",
                "map_file = subfolder_dir + '/map2pos.pkl'\n",
                "cluster_file = subfolder_dir + '/clusters_'+type_clustering+'_'+str(dist)+'_'+subfolder_dir+'_19.pkl'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [{
                "data": {
                    "text/plain": [
                        "'01-06-2022/clusters_optics_0.13_01-06-2022_19.pkl'"
                    ]
                },
                "execution_count": 37,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "cluster_file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {},
            "outputs": [{
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(9069, 2)\n",
                        "(8958, 2)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\ludov\\anaconda3\\envs\\ada\\lib\\site-packages\\sklearn\\cluster\\_optics.py:804: RuntimeWarning: divide by zero encountered in true_divide\n",
                        "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(8958, 2)\n",
                        "-1      7032\n",
                        " 32       10\n",
                        " 87        9\n",
                        " 209       9\n",
                        " 33        8\n",
                        "        ... \n",
                        " 143       2\n",
                        " 491       2\n",
                        " 56        2\n",
                        " 467       2\n",
                        " 264       2\n",
                        "Name: cluster, Length: 743, dtype: int64 743\n",
                        "(8958, 3)\n"
                    ]
                }
            ],
            "source": [
                "clusters = make_clusters_embeddings(data_dir, dist=dist, data_file=data_file, embed_file=embeds_file, type_clustering=type_clustering, dist2=dist2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(data_dir + cluster_file, 'wb') as outfile:\n",
                "    pickle.dump(clusters, outfile)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "metadata = pd.read_csv(data_dir + data_file)#.drop(columns=['level_0'])# 'data_sample.csv')\n",
                "positives = update_morph(data_dir, '-2022') "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {},
            "outputs": [{
                "data": {
                    "text/plain": [
                        "{'precision': 0.8751049215334928, 'recall': 0.6927697719027279}"
                    ]
                },
                "execution_count": 41,
                "metadata": {},
                "output_type": "execute_result"
            }],
            "source": [
                "cluster_morph_scores = evaluate_morph(positives, cluster_file, set_splits = ['test', 'val'])\n",
                "cluster_morph_scores"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Getting 2d position for visual clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": [
                "map2pos = get_2d_pos(data_dir, embed_file=embeds_file)\n",
                "with open(data_dir + map_file, 'wb') as outfile:\n",
                "    pickle.dump(map2pos, outfile)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retraining\n",
                "\n",
                "Annotation based scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [{
                "name": "stdout",
                "output_type": "stream",
                "text": [
                    "25-05-2022 {'original size': 4966, 'newly added': 224, 'additions to existing clusters': 136, 'number of clusters with new elements': 46, 'new clusters': 36, 'new clusters elements': 88, 'progress': '4.51%'}\n",
                    "25-05-2022 0.41\n",
                    "28-05-2022 {'original size': 4966, 'newly added': 217, 'additions to existing clusters': 163, 'number of clusters with new elements': 53, 'new clusters': 16, 'new clusters elements': 54, 'progress': '4.37%'}\n",
                    "28-05-2022 0.44\n",
                    "01-06-2022 {'original size': 4966, 'newly added': 212, 'additions to existing clusters': 186, 'number of clusters with new elements': 48, 'new clusters': 9, 'new clusters elements': 26, 'progress': '4.27%'}\n",
                    "01-06-2022 0.51\n"
                ]
            }],
            "source": [
                "for subfolder_dir in ['25-05-2022', '28-05-2022', '01-06-2022']:\n",
                "    \n",
                "    positives = update_morph(data_dir, subfolder_dir)\n",
                "    novelty_scores = novelty_score(positives, subfolder_dir)\n",
                "    print(subfolder_dir, novelty_scores)\n",
                "\n",
                "    morpho_graph_clusters = pd.read_csv(data_dir + 'morphograph_clusters.csv')\n",
                "    morpho_graph_clusters = morpho_graph_clusters[morpho_graph_clusters['cluster_file'].str.contains(subfolder_dir)]\n",
                "\n",
                "    scores_clusters = cluster_accuracy(morpho_graph_clusters)\n",
                "    print(subfolder_dir, scores_clusters)\n",
                "\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [{
                "name": "stdout",
                "output_type": "stream",
                "text": [
                    "07-06-2022 {'original size': 4966, 'newly added': 42, 'additions to existing clusters': 8, 'number of clusters with new elements': 6, 'new clusters': 8, 'new clusters elements': 34, 'progress': '0.85%'}\n",
                    "07-06-2022 0.99\n"
                ]
            }],
            "source": [
                "for subfolder_dir in ['07-06-2022']:\n",
                "    \n",
                "    positives = update_morph(data_dir, subfolder_dir)\n",
                "    novelty_scores = novelty_score(positives, subfolder_dir)\n",
                "    print(subfolder_dir, novelty_scores)\n",
                "\n",
                "    morpho_graph_clusters = pd.read_csv(data_dir + 'morphograph_clusters.csv')\n",
                "    morpho_graph_clusters = morpho_graph_clusters[morpho_graph_clusters['cluster_file'].str.contains(subfolder_dir)]\n",
                "\n",
                "    scores_clusters = cluster_accuracy(morpho_graph_clusters)\n",
                "    print(subfolder_dir, scores_clusters)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [{
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "25-05-2022\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13028/13028 [01:08<00:00, 189.20it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "all positions 200.63960298654268\n",
                        "min positions 63.51210898082745\n",
                        "median positions 205.69374369323916\n",
                        "mean average precision 0.42130403841280356\n",
                        "recall @ 400 0.77763527381736\n",
                        "recall @ 200 0.7180536846504237\n",
                        "recall @ 100 0.6583113652859789\n",
                        "recall @ 50 0.5929899953228329\n",
                        "recall @ 20 0.5058607889858885\n",
                        "28-05-2022\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13028/13028 [01:08<00:00, 190.35it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "all positions 203.44011266598113\n",
                        "min positions 62.32139253279516\n",
                        "median positions 206.63925327951563\n",
                        "mean average precision 0.4041070277315487\n",
                        "recall @ 400 0.7653663023411815\n",
                        "recall @ 200 0.7272548861374608\n",
                        "recall @ 100 0.6520562339478639\n",
                        "recall @ 50 0.5890477673405604\n",
                        "recall @ 20 0.49320241250773944\n",
                        "01-06-2022\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 13028/13028 [01:02<00:00, 207.57it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "all positions 205.89131309518487\n",
                        "min positions 61.12865792129163\n",
                        "median positions 210.72073662966702\n",
                        "mean average precision 0.40791816048701385\n",
                        "recall @ 400 0.7829580650169901\n",
                        "recall @ 200 0.720258031442242\n",
                        "recall @ 100 0.65470614163455\n",
                        "recall @ 50 0.5832405151719773\n",
                        "recall @ 20 0.4948517078250467\n"
                    ]
                }
            ],
            "source": [
                "for subfolder_dir in ['25-05-2022', '28-05-2022', '01-06-2022']:\n",
                "    embeds_file = subfolder_dir + '/resnext-101_'+subfolder_dir+'.npy'\n",
                "    data = pd.read_csv(data_dir + data_file)\n",
                "    embeds = np.load(data_dir + embeds_file, allow_pickle=True) \n",
                "    \n",
                "    print(subfolder_dir, )\n",
                "    get_scores(embeds, data, positives, reverse_map=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [{
                "name": "stdout",
                "output_type": "stream",
                "text": [
                    "25-05-2022/clusters_dbscan_0.08_25-05-2022_19.pkl {'precision': 0.9512017990120183, 'recall': 0.7448117066907142}\n",
                    "25-05-2022/clusters_dbscan_0.08_25-05-2022_19.pkl {'precision': 0.9145997250924256, 'recall': 0.7306353565933875} train\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.8833059797345509, 'recall': 0.7007214710374794}\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.9380492941028986, 'recall': 0.7266602581711206} train\n",
                    "25-05-2022/clusters_mix_2000_25-05-2022_19.pkl {'precision': 0.8276263877419948, 'recall': 0.5715503091194502}\n",
                    "25-05-2022/clusters_mix_2000_25-05-2022_19.pkl {'precision': 0.8920945039366089, 'recall': 0.6235081938014968} train\n",
                    "28-05-2022/clusters_dbscan_0.08_28-05-2022_19.pkl {'precision': 0.9571173939604596, 'recall': 0.7469787436102108}\n",
                    "28-05-2022/clusters_dbscan_0.08_28-05-2022_19.pkl {'precision': 0.9117892954571786, 'recall': 0.7278592614865202} train\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.8833059797345509, 'recall': 0.7007214710374794}\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.9380492941028986, 'recall': 0.7266602581711206} train\n",
                    "28-05-2022/clusters_mix_2000_28-05-2022_19.pkl {'precision': 0.7767811979864412, 'recall': 0.5234712775484296}\n",
                    "28-05-2022/clusters_mix_2000_28-05-2022_19.pkl {'precision': 0.8775456727606465, 'recall': 0.611266241592271} train\n",
                    "01-06-2022/clusters_dbscan_0.08_01-06-2022_19.pkl {'precision': 0.9060931130912883, 'recall': 0.7244476916829785}\n",
                    "01-06-2022/clusters_dbscan_0.08_01-06-2022_19.pkl {'precision': 0.9171599335376706, 'recall': 0.7325557132827191} train\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.8833059797345509, 'recall': 0.7007214710374794}\n",
                    "25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl {'precision': 0.9380492941028986, 'recall': 0.7266602581711206} train\n",
                    "01-06-2022/clusters_mix_2000_01-06-2022_19.pkl {'precision': 0.7840915736310475, 'recall': 0.5603604979524118}\n",
                    "01-06-2022/clusters_mix_2000_01-06-2022_19.pkl {'precision': 0.9055854539725506, 'recall': 0.6677810860576628} train\n"
                ]
            }],
            "source": [
                "cluster_files = ['25-05-2022/clusters_dbscan_0.08_25-05-2022_19.pkl', '25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl', '25-05-2022/clusters_mix_2000_25-05-2022_19.pkl',\n",
                "                '28-05-2022/clusters_dbscan_0.08_28-05-2022_19.pkl', '25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl', '28-05-2022/clusters_mix_2000_28-05-2022_19.pkl',\n",
                "                '01-06-2022/clusters_dbscan_0.08_01-06-2022_19.pkl', '25-05-2022/clusters_optics_0.13_25-05-2022_19.pkl', '01-06-2022/clusters_mix_2000_01-06-2022_19.pkl',\n",
                "                ]\n",
                "for cluster_file in cluster_files:\n",
                "    cluster_morph_scores = evaluate_morph(positives, cluster_file , set_splits = ['test', 'val'])\n",
                "    print(cluster_file, cluster_morph_scores)\n",
                "\n",
                "    cluster_morph_scores = evaluate_morph(positives, cluster_file , set_splits = ['train'])\n",
                "    print(cluster_file, cluster_morph_scores, 'train')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Making the new train data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "metadata": {},
            "outputs": [{
                "name": "stdout",
                "output_type": "stream",
                "text": [
                    "(12825, 27)\n"
                ]
            }],
            "source": [
                "metadata = pd.read_csv(data_dir + data_file).drop(columns=['level_0'])# 'data_sample.csv')\n",
                "data = pd.concat([metadata, positives], axis=0).reset_index().groupby(['uid', 'uid_connection']).last().reset_index()\n",
                "print(data.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "data.to_csv(data_dir + 'data_retrain_' + str(effort+1) + '.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "metadata = metadata.drop(columns=['img1', 'img2', 'type', 'annotated', 'index', 'cluster', 'set', 'uid_connection'])\n",
                "embeddings = np.load(data_dir + embeds_file, allow_pickle=True) \n",
                "\n",
                "\n",
                "with open(data_dir + 'uid2path.pkl', 'rb') as infile:\n",
                "    uid2path = pickle.load(infile)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sets = make_new_train_set(embeddings, positives, morpho_graph_clusters, subfolder_dir, uid2path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_set = sets[sets['set'] == 'train']\n",
                "val_set = sets[sets['set'] == 'val']\n",
                "\n",
                "train_set.to_csv(data_dir + 'retrain_' + str(effort+1) + '_train.csv')\n",
                "val_set.sample(frac=0.1).to_csv(data_dir + 'retrain_' + str(effort+1) + '_val.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluating the re-training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "subfolder_dir = '28-05-2022'\n",
                "cluster_file = '28-05-2022/clusters_mix_2000_28-05-2022_19.pkl'\n",
                "cluster_file = '28-05-2022/clusters_optics_0.13_28-05-2022_19.pkl'\n",
                "previous_cluster_date = '25-05-2022'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [{
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3174, 7)\n",
                        "(936, 8)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'positives': 0.8636363636363636, 'negatives': 0.6164021164021164}"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "morpho_graph_clusters = pd.read_csv(data_dir + 'morphograph_clusters_old.csv')\n",
                "track_cluster_progression(morpho_graph_clusters, cluster_file, previous_cluster_date, positives)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [{
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(1720, 7)\n",
                        "(840, 8)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'positives': 0.7228915662650602, 'negatives': 0.5971830985915493}"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "subfolder_dir = '01-06-2022'\n",
                "cluster_file = '01-06-2022/clusters_mix_2000_01-06-2022_19.pkl'\n",
                "cluster_file = '01-06-2022/clusters_optics_0.13_01-06-2022_19.pkl'\n",
                "previous_cluster_date = '28-05-2022'\n",
                "\n",
                "morpho_graph_clusters = pd.read_csv(data_dir + 'morphograph_clusters_old.csv')\n",
                "track_cluster_progression(morpho_graph_clusters, cluster_file, previous_cluster_date, positives)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [{
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(3174, 7)\n",
                        "(936, 8)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'positives': 0.8636363636363636, 'negatives': 0.6481481481481481}"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "previous_cluster_date = '25-05-2022'\n",
                "\n",
                "morpho_graph_clusters = pd.read_csv(data_dir + 'morphograph_clusters_old.csv')\n",
                "track_cluster_progression(morpho_graph_clusters, cluster_file, previous_cluster_date, positives)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "4f8e3478237dc9ca2ad28b1e82aec5b5eff6967ac82a3186532ba63a72b00cf6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.12 ('thesis')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}